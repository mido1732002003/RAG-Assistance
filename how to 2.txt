Runbook
Prerequisites
Python 3.10+ (check: python --version)
Git for cloning
OS Notes:
Windows: May need Visual C++ Build Tools for some packages
macOS (Apple Silicon): Use pip install faiss-cpu --no-binary :all: if wheels fail
Linux: Works out of the box
Setup & Install
Clone and enter directory:
Bash

git clone <repo-url>
cd local-rag-assistant
Create virtual environment:
Unix/macOS:
Bash

python3 -m venv .venv
source .venv/bin/activate
Windows:
cmd

py -m venv .venv
.venv\Scripts\activate
Install dependencies:
Bash

pip install --upgrade pip
pip install -r requirements.txt
Environment Configuration
Setup environment:
Bash

cp .env.example .env
Key variables in .env:

WATCH_DIRS=./data - Folders to monitor (comma-separated)
INDEX_DIR=./var/index - Where FAISS index is stored
SQLITE_PATH=./var/rag.db - Database location
MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2 - Embedding model
OFFLINE_MODE=true - Run without external API calls
OPENAI_API_KEY= - Optional: for OpenAI LLM mode
MISTRAL_API_KEY= - Optional: for Mistral LLM mode
First Run
Download models (optional, happens automatically):
Bash

python scripts/download_models.py
Initialize database:
Bash

python scripts/migrate_db.py
Start server:
Bash

uvicorn app.main:app --reload
Open browser: http://localhost:8000/chat
API docs: http://localhost:8000/docs
Ingesting Data
Add documents:
Method 1: Watch folder (automatic)

Place files in ./data/ folder
Server watches and indexes automatically
Method 2: CLI:

Bash

python -m cli.main ingest add ./data --recursive
Method 3: Upload via API:

Bash

curl -X POST "http://localhost:8000/api/ingest/file" \
  -H "accept: application/json" \
  -F "file=@document.pdf"
Search & Chat
Web UI:
Navigate to http://localhost:8000/chat
Toggle between Offline/LLM mode (top right)
Adjust Top-K results slider
Type questions and see citations
CLI:
Bash

# Search
python -m cli.main search query "your question" -k 10

# Interactive chat
python -m cli.main chat start --mode offline
Health & Monitoring
Check health:
Bash

curl http://localhost:8000/api/health/healthz
curl http://localhost:8000/api/health/readiness
View logs:
Bash

tail -f ./var/logs/rag.log
Docker (Optional)
Build and run:
Bash

docker build -t local-rag .
docker compose up -d
Mount volumes for persistence:

./data:/app/data - Document folder
./var/index:/app/var/index - FAISS index
./var/rag.db:/app/var/rag.db - Database
5) Self-Test & Troubleshooting
Self-Test Checklist
Start server: uvicorn app.main:app --reload ✓
Create test file: echo "This is a test document about RAG systems." > ./data/test.txt ✓
Wait 2 seconds for auto-indexing ✓
Open chat: http://localhost:8000/chat ✓
Ask question: "What is this about?" ✓
Verify: Answer shows with citation to test.txt ✓
Check offline mode: Works without API keys ✓
Common Issues & Fixes
FAISS on Apple Silicon:

Bash

pip uninstall faiss-cpu
pip install faiss-cpu --no-binary :all:
PDF parsing errors:

Falls back pypdf → pdfminer.six automatically
For complex PDFs, install: pip install pdfplumber
Windows long paths:

PowerShell

# Run as Administrator
New-ItemProperty -Path "HKLM:\SYSTEM\CurrentControlSet\Control\FileSystem" -Name "LongPathsEnabled" -Value 1 -PropertyType DWORD -Force
Permission denied on WATCH_DIRS:

Check folder permissions: ls -la ./data
Run with user that has read access
Encoding issues:

Files auto-detected with chardet
Force UTF-8: Set PYTHONIOENCODING=utf-8
Reset Instructions
Full reset:

Bash

rm -rf ./var/index/* ./var/rag.db
python scripts/migrate_db.py
# Re-add documents
Cache only:

Bash

rm -rf ./var/query_cache/*
6) Final Summary
Files Created in This Review:
All __init__.py files for packages (11 files)
app/ui/templates/components/message.html
CLI command implementations (5 files)
cli/utils.py
Evaluation datasets and runners (4 files)
Complete test suite (9 test files)
.gitkeep files (4 files)
Files Patched:
cli/main.py - Fixed command registration
requirements.txt - Added tiktoken, aiosqlite
app/core/retrieval.py - Fixed imports
TODOs (Optional Enhancements):
MMR (Maximal Marginal Relevance) for diversity in results
HyDE (Hypothetical Document Embeddings) for query expansion
FTS5 SQLite full-text search as BM25 alternative
Multi-query fusion for better recall
Streaming responses for chat interface
Authentication layer for production deployment
The project is now complete and ready to run end-to-end with the provided runbook!